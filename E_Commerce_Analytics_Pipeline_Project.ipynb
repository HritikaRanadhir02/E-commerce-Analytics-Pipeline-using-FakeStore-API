{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **E-Commerce Analytics Pipeline Using FakeStore API**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2fTgV6Ywe1SH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DySNpDpWZJEK",
        "outputId": "95704731-e4d1-4088-876a-e2ccbd8003ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing extract.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile extract.py\n",
        "import requests\n",
        "import logging\n",
        "from typing import List, Dict\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class DataExtractor:\n",
        "    \"\"\"\n",
        "    Extracts product data from FakeStore API with retry and validation handling.\n",
        "    \"\"\"\n",
        "\n",
        "    BASE_URL = \"https://fakestoreapi.com/products\"\n",
        "\n",
        "    def __init__(self, retries: int = 3, timeout: int = 10):\n",
        "        self.retries = retries\n",
        "        self.timeout = timeout\n",
        "\n",
        "    def fetch_products(self) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Fetch all product data from the API.\n",
        "        Includes error handling and retry logic.\n",
        "        \"\"\"\n",
        "        attempt = 0\n",
        "\n",
        "        while attempt < self.retries:\n",
        "            try:\n",
        "                logging.info(f\"Fetching product data... Attempt {attempt + 1}\")\n",
        "\n",
        "                response = requests.get(self.BASE_URL, timeout=self.timeout)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    logging.info(\"Data fetched successfully.\")\n",
        "                    return response.json()\n",
        "\n",
        "                logging.warning(f\"Unexpected status code: {response.status_code}\")\n",
        "\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                logging.error(f\"Request failed due to: {e}\")\n",
        "\n",
        "            attempt += 1\n",
        "\n",
        "        logging.error(\"Failed to fetch data after multiple retries.\")\n",
        "        return []\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile transform.py\n",
        "import pandas as pd\n",
        "import logging\n",
        "from typing import List, Dict\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class DataTransformer:\n",
        "    \"\"\"\n",
        "    Transforms raw product JSON into a clean Pandas DataFrame.\n",
        "    Adds derived metrics useful for analysis and reporting.\n",
        "    \"\"\"\n",
        "\n",
        "    def json_to_dataframe(self, data: List[Dict]) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Converts JSON into DataFrame with cleaning + new features.\n",
        "        \"\"\"\n",
        "\n",
        "        if not data:\n",
        "            logging.error(\"Empty data received for transformation.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        logging.info(\"Transforming JSON data into DataFrame...\")\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        # -------- FLATTEN NESTED COLUMNS --------\n",
        "        if 'rating' in df.columns:\n",
        "            df['rating_rate'] = df['rating'].apply(lambda x: x.get('rate') if isinstance(x, dict) else None)\n",
        "            df['rating_count'] = df['rating'].apply(lambda x: x.get('count') if isinstance(x, dict) else None)\n",
        "            df.drop(columns=['rating'], inplace=True)\n",
        "\n",
        "        # -------------------------------\n",
        "        # Basic cleaning\n",
        "        # -------------------------------\n",
        "        df.dropna(subset=['title', 'price'], inplace=True)  # essential fields\n",
        "        df['category'] = df['category'].str.title()\n",
        "\n",
        "        # -------------------------------\n",
        "        # Derived columns\n",
        "        # -------------------------------\n",
        "        df['price_with_tax'] = df['price'] * 1.18     # 18% estimated tax\n",
        "        df['title_length'] = df['title'].str.len()\n",
        "\n",
        "        # Category price ranking\n",
        "        df['category_avg_price'] = df.groupby('category')['price'].transform('mean')\n",
        "\n",
        "        logging.info(\"Transformation completed successfully.\")\n",
        "        return df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9hbnkXFe8_U",
        "outputId": "044e391e-2b54-4c13-e1da-ce72b1270a03"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting transform.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile analysis.py\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class DataAnalyzer:\n",
        "    \"\"\"\n",
        "    Performs insights & summary analysis on product data.\n",
        "    \"\"\"\n",
        "\n",
        "    def generate_insights(self, df: pd.DataFrame) -> str:\n",
        "        \"\"\"\n",
        "        Returns a text summary of insights.\n",
        "        \"\"\"\n",
        "\n",
        "        logging.info(\"Generating insights...\")\n",
        "\n",
        "        insights = []\n",
        "\n",
        "        insights.append(f\"Total products: {len(df)}\")\n",
        "        insights.append(f\"Number of categories: {df['category'].nunique()}\")\n",
        "\n",
        "        top_cat = df.groupby('category')['price'].mean().idxmax()\n",
        "        insights.append(f\"Highest avg price category: {top_cat}\")\n",
        "\n",
        "        cheap_prod = df.loc[df['price'].idxmin()]\n",
        "        insights.append(f\"Cheapest product: {cheap_prod['title']} (${cheap_prod['price']})\")\n",
        "\n",
        "        expensive_prod = df.loc[df['price'].idxmax()]\n",
        "        insights.append(f\"Most expensive product: {expensive_prod['title']} (${expensive_prod['price']})\")\n",
        "\n",
        "        return \"\\n\".join(insights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOgbbaROfHVj",
        "outputId": "4519374a-87ce-4f31-f766-72113e4ace46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing analysis.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile load.py\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"\n",
        "    Saves cleaned data to CSV and SQLite database.\n",
        "    \"\"\"\n",
        "\n",
        "    def save_to_csv(self, df: pd.DataFrame, filepath: str = \"output/products.csv\"):\n",
        "        df.to_csv(filepath, index=False)\n",
        "        logging.info(f\"Data saved to CSV at: {filepath}\")\n",
        "\n",
        "    def save_to_sqlite(self, df: pd.DataFrame, db_path: str = \"output/products.db\"):\n",
        "        conn = sqlite3.connect(db_path)\n",
        "        df.to_sql(\"products\", conn, if_exists=\"replace\", index=False)\n",
        "        conn.close()\n",
        "        logging.info(f\"Data stored in SQLite DB: {db_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_t0-snZfKHN",
        "outputId": "d94b66e1-5a7b-480c-d471-b76ed6c18b09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing load.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "from extract import DataExtractor\n",
        "from transform import DataTransformer\n",
        "from analysis import DataAnalyzer\n",
        "from load import DataLoader\n",
        "\n",
        "import os\n",
        "\n",
        "def ensure_output_folder():\n",
        "    if not os.path.exists(\"output\"):\n",
        "        os.makedirs(\"output\")\n",
        "\n",
        "def main():\n",
        "    ensure_output_folder()\n",
        "\n",
        "    # Step 1: Extract\n",
        "    extractor = DataExtractor()\n",
        "    raw_data = extractor.fetch_products()\n",
        "\n",
        "    # Step 2: Transform\n",
        "    transformer = DataTransformer()\n",
        "    df = transformer.json_to_dataframe(raw_data)\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"No data to process.\")\n",
        "        return\n",
        "\n",
        "    # Step 3: Analyze\n",
        "    analyzer = DataAnalyzer()\n",
        "    insights = analyzer.generate_insights(df)\n",
        "\n",
        "    with open(\"output/summary.txt\", \"w\") as f:\n",
        "        f.write(insights)\n",
        "\n",
        "    print(\"Insights generated:\\n\", insights)\n",
        "\n",
        "    # Step 4: Load (CSV + SQLite)\n",
        "    loader = DataLoader()\n",
        "    loader.save_to_csv(df)\n",
        "    loader.save_to_sqlite(df)\n",
        "\n",
        "    print(\"\\nPipeline executed successfully!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3pjEBaNfRMQ",
        "outputId": "ef76acb7-58a4-43d5-ebdd-b60e0daca5cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyG5wYWRfa3m",
        "outputId": "ceb0c95f-ce8d-4392-d8ca-3fd22b8eebb0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-25 05:48:26,950 - INFO - NumExpr defaulting to 2 threads.\n",
            "2025-11-25 05:48:27,164 - INFO - Fetching product data... Attempt 1\n",
            "2025-11-25 05:48:27,440 - INFO - Data fetched successfully.\n",
            "2025-11-25 05:48:27,441 - INFO - Transforming JSON data into DataFrame...\n",
            "2025-11-25 05:48:27,449 - INFO - Transformation completed successfully.\n",
            "2025-11-25 05:48:27,449 - INFO - Generating insights...\n",
            "Insights generated:\n",
            " Total products: 20\n",
            "Number of categories: 4\n",
            "Highest avg price category: Electronics\n",
            "Cheapest product: Opna Women's Short Sleeve Moisture ($7.95)\n",
            "Most expensive product: Samsung 49-Inch CHG90 144Hz Curved Gaming Monitor (LC49HG90DMNXZA) â€“ Super Ultrawide Screen QLED  ($999.99)\n",
            "2025-11-25 05:48:27,454 - INFO - Data saved to CSV at: output/products.csv\n",
            "2025-11-25 05:48:27,492 - INFO - Data stored in SQLite DB: output/products.db\n",
            "\n",
            "Pipeline executed successfully!\n"
          ]
        }
      ]
    }
  ]
}